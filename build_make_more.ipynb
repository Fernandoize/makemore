{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a92ca6d-0790-473f-a492-f1ee09685d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a98cfb-ed16-4f99-a1a6-5ff2c2d2f93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d327146-f06f-4f92-a198-5f782246f8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4d5504-1d0e-469d-9cc9-6269180d8976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d991d21-4b00-4871-8659-2d5a49fd8a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a6260c-7176-4ced-8f0a-04a40b043779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单词拆分\n",
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = (ch1, ch2)\n",
    "        b[bigram]  = b.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c1c0ab-0c49-4a76-8ddd-4c14f8ea7a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08a60cc1-2f13-4e36-811e-606a27efad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af7e961a-b6a8-4f75-94af-abe6608f7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tensor矩阵存储对应的字母表\n",
    "N = torch.zeros((27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc2b82dc-0e19-40da-ab5b-ff8b1248b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建字母到index的映射\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a178584e-0c75-467c-8f7e-ba78b385cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7474c8-9a96-4955-9945-bfcfcbcd7afb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m ix1 \u001b[38;5;241m=\u001b[39m stoi[ch1]\n\u001b[1;32m      5\u001b[0m ix2 \u001b[38;5;241m=\u001b[39m stoi[ch2]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mN\u001b[49m[ix1, ix2] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2cc9bb-c9e3-475d-bb27-34c9ae72ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36be52c9-c477-494e-b33a-2c117b9614c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mN\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m27\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m27\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画模型矩阵图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, N[i,j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c0f00f-18aa-472c-8360-385f767af59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0, 1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3de6f51-7118-4763-a1a7-6cd65864c767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p /= p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82397134-4f67-4526-a6c8-47d587a5cbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1,replacement=True,generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f55005-7eab-44f0-abfb-509f7b76cc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7298db99-4158-422e-beb2-066ae9969091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6064, 0.3033, 0.0903])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "p = torch.rand(3, generator=g)\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dfedfcd-6022-440c-a197-e22164c40dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 13, 16,  2,  9, 14, 12, 14, 19, 21,  9,  5,  8, 18, 14,  0,  0, 25,\n",
       "         4,  0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(p, num_samples=20,replacement=True,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f33cf5fb-ff00-4b46-a40d-9c4a95a04f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型概率\n",
    "# 为了使模型更加的平滑，给所有的count + 1，这样就不会出现log无限大的值\n",
    "P = (N+1).float()\n",
    "P /= P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baf542ad-2636-453d-90e0-1e64a642a664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e70e4d72-bd0d-4a47-b951-ac7d99bfd3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axx.\n",
      "minaymoryles.\n",
      "kondlaisah.\n",
      "anchshizarie.\n"
     ]
    }
   ],
   "source": [
    "# 尝试根据概率参数输出单词\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        ix = torch.multinomial(p, num_samples=1,replacement=True,generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0100e851-8fde-42c2-b131-d3ef2e77bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".j: 0.0756 -2.5826\n",
      "ja: 0.5036 -0.6860\n",
      "ac: 0.0139 -4.2767\n",
      "ck: 0.0891 -2.4183\n",
      "kq: 0.0002 -8.5305\n",
      "q.: 0.0970 -2.3331\n",
      "log_likelihood=tensor(-20.8273)\n",
      "nll=tensor(20.8273)\n",
      "3.4712085723876953\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的概率相似性 Products of likelihoods\n",
    "# https://en.wikipedia.org/wiki/Likelihood_function\n",
    "\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in [\"jackq\"]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1,ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        # log(a*b*c) = log(a) + log(b) + log(c)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
    "\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb3b5ae3-113b-4710-8f37-2a23148bdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(a*b*c) = log(a) + log(b) + log(c)\n",
    "# Goal: maxmize likelihood of the data with ehe model parameters (likelihood equal inner product)\n",
    "# equal to maximizing the log likelihood (because log is monotonic)\n",
    "# equal to minimizing the negative log likelihood\n",
    "# euqal to minimizing the average negative log likelihood\n",
    "# 也就是说我们需要训练一个模型，其参数的概率值和数据中的概率值相似度最高，这样就能产生类似的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1f2edc3-327c-4a3c-89c0-36fa9d305afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# 我们的目的是训练一个模型，当输入一个字母时，能够根据概率预测下一个字母可能是什么\n",
    "\n",
    "# create the training set of bigrams (x, y) x为当前的字母index, y为下一个字母的index\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        print(ch1, ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "751476c1-a167-4e64-83bc-25a89843c696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "914a8622-b392-4a5b-acd3-05faabfb5d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9a087fa5-7227-4c21-bd3d-6481e0c28382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化27个神经元，每个神经元接受27个inputs (one hot的shape为27)\n",
    "g = torch.Generator().manual_seed(2147483647 + 1)\n",
    "W = torch.randn((27, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0daa82-fbd1-46c5-b6aa-ee0b4d289643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "65fbd3b9-cec6-44d9-ad6f-0c555343082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将xs转化为one hot\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # 输入 one hot 编码\n",
    "# (5, 27) @ (27, 27) = (5, 27) \n",
    "logits = (xenc @ W) # 预测 log-counts\n",
    "# softmax\n",
    "counts = logits.exp() # counts equals to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # 下一个字符的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e9cad-fd36-4d3c-bdb7-77b3918a8b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3213cb-11cd-4201-a4d1-783fac9c7b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nlls \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# i-th bigram\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     x \u001b[38;5;241m=\u001b[39m xs[i]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# input character index\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    # i-th bigram\n",
    "    x = xs[i].item() # input character index\n",
    "    y = ys[i].item() # label character index\n",
    "    print('------')\n",
    "    print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x}, {y})')\n",
    "    print('input to the neural net:', x)\n",
    "    print('output probabilities from the neural net:', probs[i])\n",
    "    print('label (actual next character):', y)\n",
    "    p = probs[i, y]\n",
    "    print('probability assigned by the net to the correct character: ', p.item())\n",
    "    logp = torch.log(p)\n",
    "    print('log lokelihood:', logp.item())\n",
    "    nll = -logp\n",
    "    print('negative log likelihood:', nll.item())\n",
    "    nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e loss = ', nll.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f8d21c39-7adf-4bf4-9d81-5967543b6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d5bd47ed-a2e7-464a-9f3c-e577fa8df4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "defdfed7-0833-4459-9035-223df2fab974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bd2e04ff-d0d7-4051-b78e-ba69fd9991ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e21fadd5-d9de-4ff8-a6be-da0ab6f6b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass \n",
    "xenc = F.one_hot(xs, num_classes=27).float() # 输入 one hot 编码\n",
    "logits = xenc @ W # 预测 log-counts\n",
    "counts = logits.exp() # counts equals to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # 下一个字符的概率\n",
    "loss = -probs[torch.arange(5), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7b9e0c43-b410-4df5-8280-41cdee32842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.531052350997925\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d4588991-5c8a-4041-a2dc-14e9f5bbf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward oass\n",
    "W.grad = None # set to zero\n",
    "loss.backward()\n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "96de41a0-ef9a-4922-9a9b-3699f058ec6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# 最终版本\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initial\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0bb01dc-b843-43c0-af31-f470f39a550e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# gradient descent\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# forward pass \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     xenc \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mone_hot(xs, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;66;03m# 输入 one hot 编码\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     logits \u001b[38;5;241m=\u001b[39m xenc \u001b[38;5;241m@\u001b[39m W \u001b[38;5;66;03m# 预测 log-counts\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     counts \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mexp() \u001b[38;5;66;03m# counts equals to N\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "    # forward pass \n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # 输入 one hot 编码\n",
    "    logits = xenc @ W # 预测 log-counts\n",
    "    counts = logits.exp() # counts equals to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # 下一个字符的概率\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward oass\n",
    "    W.grad = None # set to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -10 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "826d670b-0f5e-4857-88aa-d3fc858f47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axx.\n",
      "minaymoryles.\n",
      "kondlaisah.\n",
      "anchshizarie.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the neural net\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        \n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float() # 输入 one hot 编码\n",
    "        logits = xenc @ W # 预测 log-counts\n",
    "        counts = logits.exp() # counts equals to N\n",
    "        p = counts / counts.sum(1, keepdims=True) # 下一个字符的概率\n",
    "        # p = P[ix]\n",
    "        ix = torch.multinomial(p, num_samples=1,replacement=True,generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(out))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b12c8-2bd9-4ef5-90bb-19b6a83465bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02240973-2766-40cf-a2bb-0475df9a51d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
